[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Modal Examples",
    "section": "",
    "text": "This is a Quarto book on notes on running Modal examples.\nThis is meant as a personal reference and not an official guide on Modal.\nAll credit should be given to the Modal team for a wonderful tool and example setup."
  },
  {
    "objectID": "01_getting_started.html",
    "href": "01_getting_started.html",
    "title": "2¬† Getting Started",
    "section": "",
    "text": "3 hello_world.py\nNow we‚Äôll start with this file:\nNow let‚Äôs look at the next file:\nWe can also glance at how generators vary for remote vs local with:\nThen if we run:"
  },
  {
    "objectID": "01_getting_started.html#clone-repo",
    "href": "01_getting_started.html#clone-repo",
    "title": "2¬† Getting Started",
    "section": "2.1 Clone repo",
    "text": "2.1 Clone repo\ngit clone https://github.com/modal-labs/modal-examples.git"
  },
  {
    "objectID": "01_getting_started.html#modal-setup",
    "href": "01_getting_started.html#modal-setup",
    "title": "2¬† Getting Started",
    "section": "2.2 Modal setup",
    "text": "2.2 Modal setup\n$ modal setup\n\nThe web browser should have opened for you to authenticate and get an API token.\nIf it didn't, please copy this URL into your web browser manually:\n\nhttps://modal.com/token-flow/tf-xxxxxxxxxxx\n\nWeb authentication finished successfully!\nToken is connected to the charlotte-llm workspace.\nVerifying token against https://api.modal.com\nToken verified successfully!\nToken written to /Users/ryan/.modal.toml in profile charlotte-llm."
  },
  {
    "objectID": "01_getting_started.html#running-our-function-locally-remotely-and-in-parallel",
    "href": "01_getting_started.html#running-our-function-locally-remotely-and-in-parallel",
    "title": "2¬† Getting Started",
    "section": "3.1 Running our function locally, remotely, and in parallel",
    "text": "3.1 Running our function locally, remotely, and in parallel\nThree different ways we can call that function:\n\nAs a regular local call on your computer, with f.local\nAs a remote call that runs in the cloud, with f.remote\nBy map ping many copies of f in the cloud over many inputs, with f.map\n\n$ cd 01_getting_started\n$ modal run hello_world.py\n‚úì Initialized. View run at https://modal.com/charlotte-llm/main/apps/ap-xxxxxxxxx\n‚úì Created objects.\n‚îú‚îÄ‚îÄ üî® Created mount /modal-examples/01_getting_started/hello_world.py\n‚îî‚îÄ‚îÄ üî® Created function f.\nhello 1000\n1000000\n1000000\nhello 1000\nhello 0\nworld 1\nhello 2\nworld 3\nhello 4\nworld 5\nhello 6\nworld 7\nhello 8\nworld 9\nhello 10\nworld 11\nhello 12\nworld 13\nhello 14\nworld 15\nhello 16\nworld 17\nhello 18\nworld 19\n2470\nStopping app - local entrypoint completed.\n‚úì App completed. View run at https://modal.com/charlotte-llm/main/apps/ap-xxxxxxxxx\n\n3.1.1 What just happened?\nWhen we called .remote on f, the function was executed in the cloud, on Modal‚Äôs infrastructure, not locally on our computer.\nIn short, we took the function f, put it inside a container, sent it the inputs, and streamed back the logs and outputs.\n\n\n3.1.2 But why does this matter?\nTry doing one of these things next to start seeing the full power of Modal!\n\n\n3.1.3 Change the code\nI‚Äôll change the print to ‚Äúspam‚Äù and ‚Äúeggs‚Äù:\n\n\nhello_world_spam.py\n\nimport sys\nimport modal\n\napp = modal.App(\"example-hello-world\")\n\n@app.function()\ndef f(i):\n    if i % 2 == 0:\n        print(\"spam\", i)\n    else:\n        print(\"eggs\", i, file=sys.stderr)\n\n    return i * i\n\n@app.local_entrypoint()\ndef main():\n    # run the function locally\n    print(f.local(1000))\n\n    # run the function remotely on Modal\n    print(f.remote(1000))\n\n    # run the function in parallel and remotely on Modal\n    total = 0\n    for ret in f.map(range(20)):\n        total += ret\n\n    print(total)\n\nThen run:\n$ modal run hello_world_spam.py\n‚úì Initialized. View run at https://modal.com/charlotte-llm/main/apps/ap-xxxxxxxxx\n‚úì Created objects.\n‚îú‚îÄ‚îÄ üî® Created mount /modal-examples/01_getting_started/hello_world_spam.py\n‚îî‚îÄ‚îÄ üî® Created function f.\nspam 1000\n1000000\nspam 1000\n1000000\nspam 0\neggs 1\nspam 2\neggs 3\nspam 4\neggs 5\nspam 6\neggs 7\nspam 8\neggs 9\nspam 10\neggs 11\nspam 12\neggs 13\nspam 14\neggs 15\nspam 16\neggs 17\nspam 18\neggs 19\n2470\nStopping app - local entrypoint completed.\n‚úì App completed. View run at https://modal.com/charlotte-llm/main/apps/ap-xxxxxxxxx\nI can view the output via browser:\n\nThis example is obviously very simple, but there are many other things you can do with modal like:\n\nRunning language model inference or fine-tuning\nManipulating audio or images\nCollecting financial data to backtest a trading algorithm."
  },
  {
    "objectID": "01_getting_started.html#decorators",
    "href": "01_getting_started.html#decorators",
    "title": "2¬† Getting Started",
    "section": "4.1 Decorators",
    "text": "4.1 Decorators\nNotice the two different app decorators: @app.function() and @app.local_entrypoint().\n\n\n\n\n\n\nFrom the docs, a local_entrypoint:\n\n\n\n&gt; def local_entrypoint(\n    self, _warn_parentheses_missing=None, *, name: Optional[str] = None\n) -&gt; Callable[[Callable[..., Any]], None]:\nDecorate a function to be used as a CLI entrypoint for a Modal App.\nThese functions can be used to define code that runs locally to set up the app, and act as an entrypoint to start Modal functions from. Note that regular Modal functions can also be used as CLI entrypoints, but unlike local_entrypoint, those functions are executed remotely directly.\n@app.local_entrypoint()\ndef main():\n    some_modal_function.remote()\nYou can call the function using modal run directly from the CLI:\nmodal run app_module.py\nNote that an explicit app.run() is not needed, as an app is automatically created for you.\n\n\nWe can run:\n$ modal run get_started.py     \n‚úì Initialized. View run at https://modal.com/charlotte-llm/main/apps/ap-xxxxxxxxx\n‚úì Created objects.\n‚îú‚îÄ‚îÄ üî® Created mount /modal-examples/01_getting_started/get_started.py\n‚îî‚îÄ‚îÄ üî® Created function square.\nthe square is 1764\nThis code is running on a remote worker!\nStopping app - local entrypoint completed.\n‚úì App completed. View run at https://modal.com/charlotte-llm/main/apps/ap-xxxxxxxxx\nNow I wonder what happens if I create a similar new file:\n\n\nget_started_local.py\n\nimport modal\n\napp = modal.App(\"example-get-started-local\")\n\n\n@app.function()\ndef square(x):\n    print(\"This code is running on a local worker!\")\n    return x**2\n\n\n@app.local_entrypoint()\ndef main():\n    print(\"the square is\", square.local(42))\n\nAnd then run:\n$ modal run get_started_local.py\n‚úì Initialized. View run at https://modal.com/charlotte-llm/main/apps/ap-xxxxxxxxxx\n‚úì Created objects.\n‚îú‚îÄ‚îÄ üî® Created mount /modal-examples/01_getting_started/get_started_local.py\n‚îî‚îÄ‚îÄ üî® Created function square.\nThis code is running on a local worker!\nthe square is 1764\nStopping app - local entrypoint completed.\n‚úì App completed. View run at https://modal.com/charlotte-llm/main/apps/ap-xxxxxxxxxx\nVery similar. What happens when we look at the logs:"
  },
  {
    "objectID": "02_building_containers.html#import_sklearn.py",
    "href": "02_building_containers.html#import_sklearn.py",
    "title": "3¬† Building Containers",
    "section": "3.1 import_sklearn.py",
    "text": "3.1 import_sklearn.py\n\n3.1.1 Install scikit-learn in a custom image\nThis builds a custom image which installs the sklearn (scikit-learn) Python package in it. It‚Äôs an example of how you can use packages, even if you don‚Äôt have them installed locally.\nFirst, the imports:\nimport time\nimport modal\nNext, we‚Äôll define an app, with a custom image that installs sklearn.\napp = modal.App(\n    \"import-sklearn\",\n    image=modal.Image.debian_slim()\n    .apt_install(\"libgomp1\")\n    .pip_install(\"scikit-learn\"),\n)\n\n\n\n\n\n\nChaining\n\n\n\nA nice design in modal is the idea of method chaining, where the image is built by layers.\n\n\nThe app.image.imports() lets us conditionally import in the global scope. This is needed because we might not have sklearn and numpy installed locally, but we know they are installed inside the custom image.\nwith app.image.imports():\n    import numpy as np\n    from sklearn import datasets, linear_model\nNow, let‚Äôs define a function that uses one of scikit-learn‚Äôs built-in datasets and fits a very simple model (linear regression) to it.\n@app.function()\ndef fit():\n    print(\"Inside run!\")\n    t0 = time.time()\n    diabetes_X, diabetes_y = datasets.load_diabetes(return_X_y=True)\n    diabetes_X = diabetes_X[:, np.newaxis, 2]\n    regr = linear_model.LinearRegression()\n    regr.fit(diabetes_X, diabetes_y)\n    return time.time() - t0\nFinally, we‚Äôd trigger the run locally. We also time this. Note that the first time we run this, it will build the image. This might take 1-2 min. When we run this subsequent times, the image is already build, and it will run much much faster.\nif __name__ == \"__main__\":\n    t0 = time.time()\n    with app.run():\n        t = fit.remote()\n        print(\"Function time spent:\", t)\n    print(\"Full time spent:\", time.time() - t0)\nLet‚Äôs now run it all:\n$ modal run import_sklearn.py \n‚úì Initialized. View run at https://modal.com/charlotte-llm/main/apps/ap-xxxxxxxxxx\nBuilding image im-m9EoOtS0dmWsGUat8WCWFc\n\n=&gt; Step 0: FROM base\n\n=&gt; Step 1: RUN apt-get update\nGet:1 http://deb.debian.org/debian bullseye InRelease [116 kB]\nGet:2 http://deb.debian.org/debian-security bullseye-security InRelease [48.4 kB]\nGet:3 http://deb.debian.org/debian bullseye-updates InRelease [44.1 kB]\nGet:4 http://deb.debian.org/debian bullseye/main amd64 Packages [8068 kB]\nGet:5 http://deb.debian.org/debian-security bullseye-security/main amd64 Packages [275 kB]\nGet:6 http://deb.debian.org/debian bullseye-updates/main amd64 Packages.diff/Index [26.3 kB]\nGet:7 http://deb.debian.org/debian bullseye-updates/main amd64 Packages T-2023-12-29-1403.39-F-2023-07-31-2005.11.pdiff [6053 B]\nGet:7 http://deb.debian.org/debian bullseye-updates/main amd64 Packages T-2023-12-29-1403.39-F-2023-07-31-2005.11.pdiff [6053 B]\nGet:8 http://deb.debian.org/debian bullseye-updates/main amd64 Packages [18.8 kB]\nFetched 8602 kB in 4s (2239 kB/s)\nReading package lists...\n\n=&gt; Step 2: RUN apt-get install -y libgomp1\nReading package lists...\nBuilding dependency tree...\nReading state information...\nlibgomp1 is already the newest version (10.2.1-6).\nlibgomp1 set to manually installed.\n0 upgraded, 0 newly installed, 0 to remove and 46 not upgraded.\nCreating image snapshot...\nFinished snapshot; took 1.14s\n\nBuilt image im-m9EoOtS0dmWsGUat8WCWFc in 8.53s\nBuilding image im-Kndkz3TpRhPEMy6UcNR7YR\n\n=&gt; Step 0: FROM base\n\n=&gt; Step 1: RUN python -m pip install scikit-learn \nLooking in indexes: http://pypi-mirror.modal.local:5555/simple\nCollecting scikit-learn\n  Downloading http://pypi-mirror.modal.local:5555/simple/scikit-learn/scikit_learn-1.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.3 MB)\n     ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 13.3/13.3 MB 169.9 MB/s eta 0:00:00\nRequirement already satisfied: numpy&gt;=1.19.5 in /usr/local/lib/python3.10/site-packages (from scikit-learn) (1.25.0)\nCollecting scipy&gt;=1.6.0 (from scikit-learn)\n  Downloading http://pypi-mirror.modal.local:5555/simple/scipy/scipy-1.13.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.6 MB)\n     ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 38.6/38.6 MB 233.1 MB/s eta 0:00:00\nCollecting joblib&gt;=1.2.0 (from scikit-learn)\n  Downloading http://pypi-mirror.modal.local:5555/simple/joblib/joblib-1.4.2-py3-none-any.whl (301 kB)\n     ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 301.8/301.8 kB 252.9 MB/s eta 0:00:00\nCollecting threadpoolctl&gt;=3.1.0 (from scikit-learn)\n  Downloading http://pypi-mirror.modal.local:5555/simple/threadpoolctl/threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\nInstalling collected packages: threadpoolctl, scipy, joblib, scikit-learn\nSuccessfully installed joblib-1.4.2 scikit-learn-1.5.0 scipy-1.13.1 threadpoolctl-3.5.0\n\n[notice] A new release of pip is available: 23.1.2 -&gt; 24.0\n[notice] To update, run: pip install --upgrade pip\nCreating image snapshot...\nFinished snapshot; took 2.27s\n\nBuilt image im-Kndkz3TpRhPEMy6UcNR7YR in 13.14s\n‚úì Created objects.\n‚îú‚îÄ‚îÄ üî® Created mount /modal-examples/02_building_containers/import_sklearn.py\n‚îî‚îÄ‚îÄ üî® Created function fit.\nInside run!\nStopping app - local entrypoint completed.\n‚úì App completed. View run at https://modal.com/charlotte-llm/main/apps/ap-xxxxxxxxxx\nSo from the above, it took 8.53s to build the first image, 2.27s to create the snapshot and 13.14s to build the second image. But if we run this again, it‚Äôll be much faster than before as we‚Äôve already."
  },
  {
    "objectID": "02_building_containers.html#import_sklearn_r2.py",
    "href": "02_building_containers.html#import_sklearn_r2.py",
    "title": "3¬† Building Containers",
    "section": "3.2 import_sklearn_r2.py",
    "text": "3.2 import_sklearn_r2.py\nJust for fun, let‚Äôs modify this script to now output the R^2 value on the test data.\n\n\nimport_sklearn_r2.py\n\nimport time\nimport modal\n\napp = modal.App(\n    \"import-sklearn\",\n    image=modal.Image.debian_slim()\n    .apt_install(\"libgomp1\")\n    .pip_install(\"scikit-learn\"),\n)\n\nwith app.image.imports():\n    import numpy as np\n    from sklearn import datasets, linear_model\n    from sklearn.model_selection import train_test_split\n    from sklearn.metrics import r2_score\n\n@app.function()\ndef fit():\n    print(\"Inside run!\")\n    X, y = datasets.load_diabetes(return_X_y=True)\n    X = X[:, np.newaxis, 2]\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n    regr = linear_model.LinearRegression()\n    regr.fit(X_train, y_train)\n    predict = regr.predict(X_test)\n    \n    return r2_score(predict, y_test)\n\n\nif __name__ == \"__main__\":\n    t0 = time.time()\n    with app.run():\n        t = fit.remote()\n        print(\"R Squared is:\", t)\n    print(\"Full time spent:\", time.time() - t0)\n\nRunning this, we get:\n$ modal run import_sklearn_r2.py\n‚úì Initialized. View run at https://modal.com/charlotte-llm/main/apps/ap-xxxxxxxxx\n‚úì Created objects.\n‚îú‚îÄ‚îÄ üî® Created mount /modal-examples/02_building_containers/import_sklearn_r2.py\n‚îî‚îÄ‚îÄ üî® Created function fit.\nInside run!\nStopping app - local entrypoint completed.\n‚úì App completed. View run at https://modal.com/charlotte-llm/main/apps/ap-xxxxxxxxxx\nThis result somewhat surprised me.\nFirst, I didn‚Äôt see the output R^2. I was expecting this perhaps the first time running, but didn‚Äôt see it.\nSecond, after running, unlike the previous example that shut down immediately, this container was running ephemerally:\n\nSo let‚Äôs rerun, but this time renaming our function from fit to fit_r2:\n$ modal run import_sklearn_r2.py\n‚úì Initialized. View run at https://modal.com/charlotte-llm/main/apps/ap-xxxxxxxxxx\n‚úì Created objects.\n‚îú‚îÄ‚îÄ üî® Created mount /modal-examples/02_building_containers/import_sklearn_r2.py\n‚îî‚îÄ‚îÄ üî® Created function fit_r2.\nInside run!\nStopping app - local entrypoint completed.\n‚úì App completed. View run at https://modal.com/charlotte-llm/main/apps/ap-xxxxxxxxxx\nThis avoided the issue of perpetually running but didn‚Äôt print the R^2 to console:\n\nInstead, I modified to put the print within the function such that:\n@app.function()\ndef fit_r2():\n    print(\"Inside run!\")\n    X, y = datasets.load_diabetes(return_X_y=True)\n    X = X[:, np.newaxis, 2]\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n    regr = linear_model.LinearRegression()\n    regr.fit(X_train, y_train)\n    predict = regr.predict(X_test)\n    r2 = r2_score(predict, y_test) \n    print(\"R squared is:\", r2) # added this\n    return r2\nWhen doing this, I now get the result I want:\n$ modal run 02_building_containers/import_sklearn_r2.py \n‚úì Initialized. View run at https://modal.com/charlotte-llm/main/apps/ap-xxxxxxxxxx\n‚úì Created objects.\n‚îú‚îÄ‚îÄ üî® Created mount /Users/ryan/Desktop/Desktop - Ryan‚Äôs iMac/personal/modal-examples/02_building_containers/import_sklearn_r2.py\n‚îî‚îÄ‚îÄ üî® Created function fit_r2.\nInside run!\nR squared is: -0.8503156043967386\nStopping app - local entrypoint completed.\n‚úì App completed. View run at https://modal.com/charlotte-llm/main/apps/ap-xxxxxxxxxx\nIt‚Äôs important to mindful of scope of local vs.¬†remote when using Modal. This will be an extended discussion we‚Äôll see in later examples."
  },
  {
    "objectID": "02_building_containers.html#install_cuda.py",
    "href": "02_building_containers.html#install_cuda.py",
    "title": "3¬† Building Containers",
    "section": "3.3 install_cuda.py",
    "text": "3.3 install_cuda.py\nThe next examples shows how to use the Nvidia CUDA base image from DockerHub.\nHere‚Äôs a list of the different CUDA images available.\nWe need to add Python 3 and pip with the add_python option because the image doesn‚Äôt have these by default.\n\n\ninstall_cuda.py\n\nfrom modal import App, Image\n\nimage = Image.from_registry(\n    \"nvidia/cuda:12.2.0-devel-ubuntu22.04\", add_python=\"3.11\"\n)\napp = App(image=image)\n\n@app.function(gpu=\"T4\")\ndef f():\n    import subprocess\n\n    subprocess.run([\"nvidia-smi\"])\n\n\n\n\n\n\n\nUse an existing container image with .from_registry\n\n\n\n\n\nYou don‚Äôt always need to start from scratch! Public registries like Docker Hub have many pre-built container images for common software packages.\nYou can use any public image in your function using Image.from_registry, so long as:\n\nPython 3.8 or above is present, and is available as python\npip is installed correctly\nThe image is built for the linux/amd64 platform\nThe image has a valid ENTRYPOINT\n\nfrom modal import Image\n\nsklearn_image = Image.from_registry(\"huanjason/scikit-learn\")\n\n@app.function(image=sklearn_image)\ndef fit_knn():\n    from sklearn.neighbors import KNeighborsClassifier\n    ...\nIf an existing image does not have either python or pip set up properly, you can still use it. Just provide a version number as the add_python argument to install a reproducible, standalone build of Python:\nfrom modal import Image\n\nimage1 = Image.from_registry(\"ubuntu:22.04\", add_python=\"3.11\")\nimage2 = Image.from_registry(\"gisops/valhalla:latest\", add_python=\"3.11\")\nThe from_registry method can load images from all public registries, such as Nvidia‚Äôs nvcr.io, AWS ECR, and GitHub‚Äôs ghcr.io.\nModal also supports access to private AWS ECR and GCP Artifact Registry images.\n\n\n\nRunning it provides:\n$ modal run install_cuda.py     \n‚úì Initialized. View run at https://modal.com/charlotte-llm/main/apps/ap-xxxxxxxxxx\nBuilding image im-NAV0762Ag7PgTCJY8XyAqb\n\n=&gt; Step 0: FROM nvidia/cuda:12.2.0-devel-ubuntu22.04\nGetting image source signatures\nCopying blob sha256:9a9dd462fc4c5ca1dd29994385be60a5bb359843fc93447331b8c97dfec99bf9\nCopying blob sha256:9fe5ccccae45d6811769206667e494085cb511666be47b8e659087c249083c3f\nCopying blob sha256:aece8493d3972efa43bfd4ee3cdba659c0f787f8f59c82fb3e48c87cbb22a12e\nCopying blob sha256:bdddd5cb92f6b4613055bcbcd3226df9821c7facd5af9a998ba12dae080ef134\nCopying blob sha256:8054e9d6e8d6718cc3461aa4172ad048564cdf9f552c8f9820bd127859aa007c\nCopying blob sha256:5324914b447286e0e6512290373af079a25f94499a379e642774245376e60885\nCopying blob sha256:95eef45e00fabd2bce97586bfe26be456b0e4b3ef3d88d07a8b334ee05cc603c\nCopying blob sha256:e2554c2d377e1176c0b8687b17aa7cbe2c48746857acc11686281a4adee35a0a\nCopying blob sha256:4640d022dbb8eb47da53ccc2de59f8f5e780ea046289ba3cffdf0a5bd8d19810\nCopying blob sha256:aa750c79a4cc745750c40a37cad738f9bcea14abb96b0c5a811a9b53f185b9c9\nCopying blob sha256:9e2de25be969afa4e73937f8283a1100f4d964fc0876c2f2184fda25ad23eeda\nCopying config sha256:fead46ae620f9febc59f92a8f1f277f502ef6dca8111ce459c154d236ee84eee\nWriting manifest to image destination\nUnpacking OCI image\n   ‚Ä¢ unpacking rootfs ...\n   ‚Ä¢ ... done\n   ‚Ä¢ unpacked image rootfs: /tmp/.tmpDUhHRA\n\n=&gt; Step 1: COPY /python/. /usr/local\n\n=&gt; Step 2: RUN ln -s /usr/local/bin/python3 /usr/local/bin/python\n\n=&gt; Step 3: ENV TERMINFO_DIRS=/etc/terminfo:/lib/terminfo:/usr/share/terminfo:/usr/lib/terminfo\n\n=&gt; Step 4: COPY /modal_requirements.txt /modal_requirements.txt\n\n=&gt; Step 5: RUN python -m pip install --upgrade pip\nLooking in indexes: http://pypi-mirror.modal.local:5555/simple\nRequirement already satisfied: pip in /usr/local/lib/python3.11/site-packages (23.2.1)\nCollecting pip\n  Obtaining dependency information for pip from http://pypi-mirror.modal.local:5555/simple/pip/pip-24.0-py3-none-any.whl.metadata\n  Downloading http://pypi-mirror.modal.local:5555/simple/pip/pip-24.0-py3-none-any.whl.metadata (3.6 kB)\nDownloading http://pypi-mirror.modal.local:5555/simple/pip/pip-24.0-py3-none-any.whl (2.1 MB)\n   ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2.1/2.1 MB 216.4 MB/s eta 0:00:00\nInstalling collected packages: pip\n  Attempting uninstall: pip\n    Found existing installation: pip 23.2.1\n    Uninstalling pip-23.2.1:\n      Successfully uninstalled pip-23.2.1\nSuccessfully installed pip-24.0\n\n=&gt; Step 6: RUN python -m pip install -r /modal_requirements.txt\nLooking in indexes: http://pypi-mirror.modal.local:5555/simple\nIgnoring cloudpickle: markers 'python_version &lt; \"3.11\"' don't match your environment\nIgnoring ddtrace: markers 'python_version &lt; \"3.11\"' don't match your environment\nCollecting aiohttp==3.8.3 (from -r /modal_requirements.txt (line 2))\n\n...\n\nCreating image snapshot...\nFinished snapshot; took 6.10s\n\nBuilt image im-NAV0762Ag7PgTCJY8XyAqb in 136.43s\n‚úì Created objects.\n‚îú‚îÄ‚îÄ üî® Created mount /modal-examples/02_building_containers/install_cuda.py\n‚îî‚îÄ‚îÄ üî® Created function f.\n\n==========\n== CUDA ==\n==========\n\nCUDA Version 12.2.0\n\nContainer image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.\n\nThis container image and its contents are governed by the NVIDIA Deep Learning Container License.\nBy pulling and using the container, you accept the terms and conditions of this license:\nhttps://developer.nvidia.com/ngc/nvidia-deep-learning-container-license\n\nA copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience.\n\nThu Jun 13 23:08:03 2024       \n+-----------------------------------------------------------------------------------------+\n| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n|-----------------------------------------+------------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n|                                         |                        |               MIG M. |\n|=========================================+========================+======================|\n|   0  Tesla T4                       On  |   00000000:36:00.0 Off |                 ERR! |\n| N/A   32C ERR!               9W /   70W |       0MiB /  15360MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n                                                                                         \n+-----------------------------------------------------------------------------------------+\n| Processes:                                                                              |\n|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n|        ID   ID                                                               Usage      |\n|=========================================================================================|\n|  No running processes found                                                             |\n+-----------------------------------------------------------------------------------------+\nStopping app - local entrypoint completed.\n‚úì App completed. View run at https://modal.com/charlotte-llm/main/apps/ap-xxxxxxxxxx\nWhile this process did take a few minutes, it‚Äôs very easy and should be very quick if rerunning.\nIt‚Äôs also helpful to note how to run a subprocess as we would in Python anyways:\nimport subprocess\n\nsubprocess.run([\"nvidia-smi\"])"
  },
  {
    "objectID": "02_building_containers.html#screenshot.py",
    "href": "02_building_containers.html#screenshot.py",
    "title": "3¬† Building Containers",
    "section": "3.4 screenshot.py",
    "text": "3.4 screenshot.py\nIn this example, we use Modal functions and the playwright package to take screenshots of websites from a list of URLs in parallel.\nYou can run this example on the command line with:\nmodal run 02_building_containers/screenshot.py --url 'https://www.youtube.com/watch?v=dQw4w9WgXcQ'\n\n\n\n\n\n\nBe sure to install playwright locally\n\n\n\nWhen I first ran screenshot.py, I received an error like:\nStopping app - uncaught exception raised locally: ExecutionError('Could not deserialize remote exception due to local error:\\nDeserialization failed because the \\'playwright\\' module is not available in the local environment.\\nThis can happen if your local environment does not have the remote exception definitions.\nIt was fixed after I installed playwright into my active local Python environment.\n\n\nThis should take a few seconds then create a /tmp/screenshots/screenshot.png file, shown below.\n\n\n\nscreenshot\n\n\n\n3.4.1 Setup\nFirst we import the Modal client library.\nimport pathlib\n\nimport modal\n\napp = modal.App(\"example-screenshot\")\n\n\n3.4.2 Define a custom image\nWe need an image with the playwright Python package as well as its chromium plugin pre-installed.\nThis requires intalling a few Debian packages, as well as setting up a new Debian repository. Modal lets you run arbitrary commands, just like in Docker:\nimage = modal.Image.debian_slim().run_commands(\n    \"apt-get update\",\n    \"apt-get install -y software-properties-common\",\n    \"apt-add-repository non-free\",\n    \"apt-add-repository contrib\",\n    \"pip install playwright==1.42.0\",\n    \"playwright install-deps chromium\",\n    \"playwright install chromium\",\n)\n\n\n3.4.3 The screenshot function\nNext, the scraping function which runs headless Chromium, goes to a website, and takes a screenshot.\nThis is a Modal function which runs inside the remote container.\n@app.function(image=image)\nasync def screenshot(url):\n    from playwright.async_api import async_playwright\n\n    async with async_playwright() as p:\n        browser = await p.chromium.launch()\n        page = await browser.new_page()\n        await page.goto(url, wait_until=\"networkidle\")\n        await page.screenshot(path=\"screenshot.png\")\n        await browser.close()\n        data = open(\"screenshot.png\", \"rb\").read()\n        print(\"Screenshot of size %d bytes\" % len(data))\n        return data\n\n\n3.4.4 Entrypoint code\nLet‚Äôs kick it off by reading a bunch of URLs from a txt file and scrape some of those.\n@app.local_entrypoint()\ndef main(url: str = \"https://modal.com\"):\n    filename = pathlib.Path(\"/tmp/screenshots/screenshot.png\")\n    data = screenshot.remote(url)\n    filename.parent.mkdir(exist_ok=True)\n    with open(filename, \"wb\") as f:\n        f.write(data)\n    print(f\"wrote {len(data)} bytes to {filename}\")\nAnd we‚Äôre done! Modal‚Äôs introductory guide also has another example of a web scraper, with more in-depth logic."
  },
  {
    "objectID": "03_scaling_out.html",
    "href": "03_scaling_out.html",
    "title": "4¬† Scaling out",
    "section": "",
    "text": "5 basic_grid_search.py\nThis example showcases a simple grid search in one dimension, where we try different parameters for a model and pick the one with the best results on a holdout set.\nThis is a simple example that uses the Yahoo! Finance API to fetch a bunch of ETFs. We do this in parallel, which demonstrates the ability to map over a set of items. In this case, we fetch 100 stocks in parallel.\nYou can run this script on the terminal with:\nIf everything goes well, it should plot something like this:\nLet‚Äôs test out what we‚Äôve learned by creating a new script.\nFor this, we‚Äôll use another scikit-learn tutorial (Gradient Boosting Regularization) but loop through a parameter (the sample size, n) and for each saving a matplotlib image from fetch_stock_prices.py.\nThis tutorial is inspired by a recent :probabl. video by Vincent Warmerdam that explored this tutorial more in detail."
  },
  {
    "objectID": "03_scaling_out.html#defining-the-image",
    "href": "03_scaling_out.html#defining-the-image",
    "title": "4¬† Scaling out",
    "section": "5.1 Defining the image",
    "text": "5.1 Defining the image\nFirst, let‚Äôs build a custom image and install scikit-learn in it.\nimport modal\n\napp = modal.App(\n    \"example-basic-grid-search\",\n    image=modal.Image.debian_slim().pip_install(\"scikit-learn~=1.2.2\"),\n)"
  },
  {
    "objectID": "03_scaling_out.html#the-modal-function",
    "href": "03_scaling_out.html#the-modal-function",
    "title": "4¬† Scaling out",
    "section": "5.2 The Modal function",
    "text": "5.2 The Modal function\nNext, define the function. Note that we use the custom image with scikit-learn in it. We also take the hyperparameter k, which is how many nearest neighbors we use.\n@app.function()\ndef fit_knn(k):\n    from sklearn.datasets import load_digits\n    from sklearn.model_selection import train_test_split\n    from sklearn.neighbors import KNeighborsClassifier\n\n    X, y = load_digits(return_X_y=True)\n    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n\n    clf = KNeighborsClassifier(k)\n    clf.fit(X_train, y_train)\n    score = float(clf.score(X_test, y_test))\n    print(\"k = %3d, score = %.4f\" % (k, score))\n    return score, k"
  },
  {
    "objectID": "03_scaling_out.html#parallel-search",
    "href": "03_scaling_out.html#parallel-search",
    "title": "4¬† Scaling out",
    "section": "5.3 Parallel search",
    "text": "5.3 Parallel search\nTo do a hyperparameter search, let‚Äôs map over this function with different values for k, and then select for the best score on the holdout set:\n@app.local_entrypoint()\ndef main():\n    # Do a basic hyperparameter search\n    best_score, best_k = max(fit_knn.map(range(1, 100)))\n    print(\"Best k = %3d, score = %.4f\" % (best_k, best_score))\nNotice the map() function, which is a parallel map over a set of inputs.\nIt takes one iterator argument per argument in the function being mapped over.\nPutting all of this together, we can run it:\n$ modal run basic_grid_search.py \n‚úì Initialized. View run at https://modal.com/charlotte-llm/main/apps/ap-xxxxxxxxxx\nBuilding image im-F71KgZSeUtGyLnboXtpDAA\n\n=&gt; Step 0: FROM base\n\n=&gt; Step 1: RUN python -m pip install 'scikit-learn~=1.2.2' \nLooking in indexes: http://pypi-mirror.modal.local:5555/simple\nCollecting scikit-learn~=1.2.2\n  Downloading http://pypi-mirror.modal.local:5555/simple/scikit-learn/scikit_learn-1.2.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.6 MB)\n     ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 9.6/9.6 MB 204.2 MB/s eta 0:00:00\nRequirement already satisfied: numpy&gt;=1.17.3 in /usr/local/lib/python3.10/site-packages (from scikit-learn~=1.2.2) (1.25.0)\nCollecting scipy&gt;=1.3.2 (from scikit-learn~=1.2.2)\n  Downloading http://pypi-mirror.modal.local:5555/simple/scipy/scipy-1.13.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.6 MB)\n     ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 38.6/38.6 MB 230.3 MB/s eta 0:00:00\nCollecting joblib&gt;=1.1.1 (from scikit-learn~=1.2.2)\n  Downloading http://pypi-mirror.modal.local:5555/simple/joblib/joblib-1.4.2-py3-none-any.whl (301 kB)\n     ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 301.8/301.8 kB 237.9 MB/s eta 0:00:00\nCollecting threadpoolctl&gt;=2.0.0 (from scikit-learn~=1.2.2)\n  Downloading http://pypi-mirror.modal.local:5555/simple/threadpoolctl/threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\nInstalling collected packages: threadpoolctl, scipy, joblib, scikit-learn\nSuccessfully installed joblib-1.4.2 scikit-learn-1.2.2 scipy-1.13.1 threadpoolctl-3.5.0\n\n[notice] A new release of pip is available: 23.1.2 -&gt; 24.0\n[notice] To update, run: pip install --upgrade pip\nCreating image snapshot...\nFinished snapshot; took 2.85s\n\nBuilt image im-F71KgZSeUtGyLnboXtpDAA in 15.78s\n‚úì Created objects.\n‚îú‚îÄ‚îÄ üî® Created mount /modal-examples/03_scaling_out/basic_grid_search.py\n‚îî‚îÄ‚îÄ üî® Created function fit_knn.\nk =   1, score = 0.9822\nk =  16, score = 0.9778\nk =  17, score = 0.9800\n\n...\n\nk =  93, score = 0.9156\nk =  28, score = 0.9711\nk =  22, score = 0.9800\nBest k =   6, score = 0.9956\nStopping app - local entrypoint completed.\n‚úì App completed. View run at https://modal.com/charlotte-llm/main/apps/ap-xxxxxxxxxx"
  },
  {
    "objectID": "03_scaling_out.html#setup",
    "href": "03_scaling_out.html#setup",
    "title": "4¬† Scaling out",
    "section": "6.1 Setup",
    "text": "6.1 Setup\nFor this image, we need:\n\nhttpx and beautifulsoup4 to fetch a list of ETFs from a HTML page\nyfinance to fetch stock prices from the Yahoo Finance API\nmatplotlib to plot the result\n\nimport io\nimport os\n\nimport modal\n\napp = modal.App(\n    \"example-fetch-stock-prices\",\n    image=modal.Image.debian_slim().pip_install(\n        \"httpx~=0.24.0\",\n        \"yfinance~=0.2.31\",\n        \"beautifulsoup4~=4.12.2\",\n        \"matplotlib~=3.7.1\",\n    ),\n)"
  },
  {
    "objectID": "03_scaling_out.html#fetch-a-list-of-tickers",
    "href": "03_scaling_out.html#fetch-a-list-of-tickers",
    "title": "4¬† Scaling out",
    "section": "6.2 Fetch a list of tickers",
    "text": "6.2 Fetch a list of tickers\nThe yfinance package does not have a way to download a list of stocks. To get a list of stocks, we parse the HTML from Yahoo Finance using Beautiful Soup and ask for the top 100 ETFs.\n@app.function()\ndef get_stocks():\n    import bs4\n    import httpx\n\n    headers = {\n        \"user-agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/81.0.4044.122 Safari/537.36\",\n        \"referer\": \"https://finance.yahoo.com/\",\n    }\n    url = \"https://finance.yahoo.com/etfs?count=100&offset=0\"\n    res = httpx.get(url, headers=headers)\n    res.raise_for_status()\n    soup = bs4.BeautifulSoup(res.text, \"html.parser\")\n    for td in soup.find_all(\"td\", {\"aria-label\": \"Symbol\"}):\n        for link in td.find_all(\"a\", {\"data-test\": \"quoteLink\"}):\n            symbol = str(link.next)\n            print(f\"Found symbol {symbol}\")\n            yield symbol"
  },
  {
    "objectID": "03_scaling_out.html#fetch-stock-prices",
    "href": "03_scaling_out.html#fetch-stock-prices",
    "title": "4¬† Scaling out",
    "section": "6.3 Fetch stock prices",
    "text": "6.3 Fetch stock prices\nNow, let‚Äôs fetch the stock data. This is the function that we will parallelize.\nIt‚Äôs fairly simple and just uses the yfinance package.\n@app.function()\ndef get_prices(symbol):\n    import yfinance\n\n    print(f\"Fetching symbol {symbol}...\")\n    ticker = yfinance.Ticker(symbol)\n    data = ticker.history(period=\"1Y\")[\"Close\"]\n    print(f\"Done fetching symbol {symbol}!\")\n    return symbol, data.to_dict()"
  },
  {
    "objectID": "03_scaling_out.html#plot-the-result",
    "href": "03_scaling_out.html#plot-the-result",
    "title": "4¬† Scaling out",
    "section": "6.4 Plot the result",
    "text": "6.4 Plot the result\nHere is our plotting code. We run this in Modal, although you could also run it locally. Note that the plotting code calls the other two functions. Since we plot the data in the cloud, we can‚Äôt display it, so we generate a PNG and return the binary content from the function.\n@app.function()\ndef plot_stocks():\n    from matplotlib import pyplot, ticker\n\n    # Setup\n    pyplot.style.use(\"ggplot\")\n    fig, ax = pyplot.subplots(figsize=(8, 5))\n\n    # Get data\n    tickers = list(get_stocks.remote_gen())\n    if not tickers:\n        raise RuntimeError(\"Retrieved zero stock tickers!\")\n    data = list(get_prices.map(tickers))\n    first_date = min((min(prices.keys()) for symbol, prices in data if prices))\n    last_date = max((max(prices.keys()) for symbol, prices in data if prices))\n\n    # Plot every symbol\n    for symbol, prices in data:\n        if len(prices) == 0:\n            continue\n        dates = list(sorted(prices.keys()))\n        prices = list(prices[date] for date in dates)\n        changes = [\n            100.0 * (price / prices[0] - 1) for price in prices\n        ]  # Normalize to initial price\n        if changes[-1] &gt; 20:\n            # Highlight this line\n            p = ax.plot(dates, changes, alpha=0.7)\n            ax.annotate(\n                symbol,\n                (last_date, changes[-1]),\n                ha=\"left\",\n                va=\"center\",\n                color=p[0].get_color(),\n                alpha=0.7,\n            )\n        else:\n            ax.plot(dates, changes, color=\"gray\", alpha=0.2)\n\n    # Configure axes and title\n    ax.yaxis.set_major_formatter(ticker.PercentFormatter())\n    ax.set_title(f\"Best ETFs {first_date.date()} - {last_date.date()}\")\n    ax.set_ylabel(f\"% change, {first_date.date()} = 0%\")\n\n    # Dump the chart to .png and return the bytes\n    with io.BytesIO() as buf:\n        pyplot.savefig(buf, format=\"png\", dpi=300)\n        return buf.getvalue()"
  },
  {
    "objectID": "03_scaling_out.html#entrypoint",
    "href": "03_scaling_out.html#entrypoint",
    "title": "4¬† Scaling out",
    "section": "6.5 Entrypoint",
    "text": "6.5 Entrypoint\nThe entrypoint locally runs the app, gets the chart back as a PNG file, and saves it to disk.\nOUTPUT_DIR = \"/tmp/\"\n\n\n@app.local_entrypoint()\ndef main():\n    os.makedirs(OUTPUT_DIR, exist_ok=True)\n    data = plot_stocks.remote()\n    filename = os.path.join(OUTPUT_DIR, \"stock_prices.png\")\n    print(f\"saving data to {filename}\")\n    with open(filename, \"wb\") as f:\n        f.write(data)\nLet‚Äôs see if we can combine what we‚Äôve learned by creating a new example."
  },
  {
    "objectID": "03_scaling_out.html#initialize-the-app",
    "href": "03_scaling_out.html#initialize-the-app",
    "title": "4¬† Scaling out",
    "section": "7.1 Initialize the App",
    "text": "7.1 Initialize the App\nLet‚Äôs first name the app and create the initial image.\nimport io\nimport os\n\nimport modal\n\napp = modal.App(\n    \"example-boosting-regularization\",\n    image=modal.Image.debian_slim()\n    .pip_install(\"scikit-learn~=1.2.2\")\n    .pip_install(\"matplotlib~=3.9.0\"),\n)\nWe needed to install matplotlib since we‚Äôre calling it in our function."
  },
  {
    "objectID": "03_scaling_out.html#define-function",
    "href": "03_scaling_out.html#define-function",
    "title": "4¬† Scaling out",
    "section": "7.2 Define function",
    "text": "7.2 Define function\nFor our function, we‚Äôll use:\n@app.function()\ndef fit_boosting(n):\n    import matplotlib.pyplot as plt\n    import numpy as np\n\n    from sklearn import datasets, ensemble\n    from sklearn.metrics import log_loss\n    from sklearn.model_selection import train_test_split\n\n    X, y = datasets.make_hastie_10_2(n_samples=n, random_state=1)\n\n    # map labels from {-1, 1} to {0, 1}\n    labels, y = np.unique(y, return_inverse=True)\n\n    # note change from 0.8 to 0.2 test dataset\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n\n    original_params = {\n        \"n_estimators\": 500,\n        \"max_leaf_nodes\": 4,\n        \"max_depth\": None,\n        \"random_state\": 2,\n        \"min_samples_split\": 5,\n    }\n\n    plt.figure()\n\n    for label, color, setting in [\n        (\"No shrinkage\", \"orange\", {\"learning_rate\": 1.0, \"subsample\": 1.0}),\n        (\"learning_rate=0.2\", \"turquoise\", {\"learning_rate\": 0.2, \"subsample\": 1.0}),\n        (\"subsample=0.5\", \"blue\", {\"learning_rate\": 1.0, \"subsample\": 0.5}),\n        (\n            \"learning_rate=0.2, subsample=0.5\",\n            \"gray\",\n            {\"learning_rate\": 0.2, \"subsample\": 0.5},\n        ),\n        (\n            \"learning_rate=0.2, max_features=2\",\n            \"magenta\",\n            {\"learning_rate\": 0.2, \"max_features\": 2},\n        ),\n    ]:\n        params = dict(original_params)\n        params.update(setting)\n\n        clf = ensemble.GradientBoostingClassifier(**params)\n        clf.fit(X_train, y_train)\n\n        # compute test set deviance\n        test_deviance = np.zeros((params[\"n_estimators\"],), dtype=np.float64)\n\n        for i, y_proba in enumerate(clf.staged_predict_proba(X_test)):\n            test_deviance[i] = 2 * log_loss(y_test, y_proba[:, 1])\n\n        plt.plot(\n            (np.arange(test_deviance.shape[0]) + 1)[::5],\n            test_deviance[::5],\n            \"-\",\n            color=color,\n            label=label,\n        )\n\n    plt.legend(loc=\"upper right\")\n    plt.xlabel(\"Boosting Iterations\")\n    plt.ylabel(\"Test Set Deviance\")\n\n        # Dump the chart to .png and return the bytes\n    with io.BytesIO() as buf:\n        plt.savefig(buf, format=\"png\", dpi=300)\n        return buf.getvalue()\nThis is primarily the scikit-learn demo but a few modifications like:\n\nwe modified the test_size from 0.8 to 0.2\nwe parameterized the sample size n, which we‚Äôll loop through\nwe‚Äôll return the chart, similarly from fetch_stock_prices.py\nincreased the number of boosting iterations from 400 to 500\n\nLast, we‚Äôll define the local_entrypoint as:\nOUTPUT_DIR = \"/tmp/modal\"\n\n\n@app.local_entrypoint()\ndef main():\n    os.makedirs(OUTPUT_DIR, exist_ok=True)\n    for n in [1000,5000,10000,20000,50000]:\n        plot = fit_boosting.remote(n)\n        filename = os.path.join(OUTPUT_DIR, f\"boosting_{n}.png\")\n        print(f\"saving data to {filename}\")\n        with open(filename, \"wb\") as f:\n            f.write(plot)\nThis will end with us saving each of the images into a folder /tmp/modal.\nSo let‚Äôs now run this:\n$ modal run boosting_regularization.py\n‚úì Initialized. View run at https://modal.com/charlotte-llm/main/apps/ap-xxxxxxxxxx\n‚úì Created objects.\n‚îú‚îÄ‚îÄ üî® Created mount /modal-examples/03_scaling_out/boosting_regularization.py\n‚îî‚îÄ‚îÄ üî® Created function fit_boosting.\nsaving data to /tmp/modal/boosting_1000.png\nsaving data to /tmp/modal/boosting_5000.png\nsaving data to /tmp/modal/boosting_10000.png\nsaving data to /tmp/modal/boosting_20000.png\nsaving data to /tmp/modal/boosting_50000.png\nStopping app - local entrypoint completed.\n‚úì App completed. View run at https://modal.com/charlotte-llm/main/apps/ap-xxxxxxxxxx\nWe can view a few of the images. For example, this is n = 5000:\n\nThis is particularly interesting due to the subsample = 0.5, which generally follows No shrinkage but then jumps up. It‚Äôs not clear why but a curious case.\nAlternatively, let‚Äôs look at n = 10000:\n\nNow we see a result consistent with Vincent‚Äôs video as all curves smooth out, none shrinkage learns quickly and then levels out very quickly. Even after 500 iterations no shrinkage has a lower deviance, which indicates a better out-of-sample fit.\nLet‚Äôs last look at n = 50000:\n\nVery similar curves again, but this time the gains of no shrinkage is even magnified more as up to 500 iterations there‚Äôs a larger gap between no shrinkage and shrinkage.\nWhat‚Äôs nice about Modal is we can also view the remote logs such that:\n\nNot surprising, our last (n = 50000) execution took the longest, taking about 4 minutes and 23 seconds. This is helpful for us to keep in mind and use these logs more as we begin to run more computationally intensive examples moving forward.\nBut there‚Äôs a problem with this setup: we‚Äôre missing out on speed gains we could get by parallelizing. Let‚Äôs instead use the .map() instead of .remote() when we call our main function:\n\n\nboosting_regularization_parallel.py\n\n...\n\n@app.local_entrypoint()\ndef main():\n    os.makedirs(OUTPUT_DIR, exist_ok=True)\n    val = [1000,5000,10000,20000,50000]\n    plots = fit_boosting.map(val)\n    for n, plot in zip(val, plots):\n        filename = os.path.join(OUTPUT_DIR, f\"boosting_{n}.png\")\n        print(f\"saving data to {filename}\")\n        with open(filename, \"wb\") as f:\n            f.write(plot)\n\nSo now when we run, all five of the calls run in parallel, yielding a much faster run time.\nWe can confirm this by looking at the logs:"
  }
]