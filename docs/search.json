[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "modal-examples",
    "section": "",
    "text": "Preface\nThis is a Quarto book on notes on running Modal examples.\nThis is meant as a personal reference and not an official guide on Modal.\nAll credit should be given to the Modal team for a wonderful tool and example setup."
  },
  {
    "objectID": "01_getting_started.html",
    "href": "01_getting_started.html",
    "title": "2¬† Getting Started",
    "section": "",
    "text": "3 hello_world.py\nNow we‚Äôll start with this file:\nNow let‚Äôs look at the next file:\nWe can also glance at how generators vary for remote vs local with:\nThen if we run:"
  },
  {
    "objectID": "01_getting_started.html#clone-repo",
    "href": "01_getting_started.html#clone-repo",
    "title": "2¬† Getting Started",
    "section": "2.1 Clone repo",
    "text": "2.1 Clone repo\ngit clone https://github.com/modal-labs/modal-examples.git"
  },
  {
    "objectID": "01_getting_started.html#modal-setup",
    "href": "01_getting_started.html#modal-setup",
    "title": "2¬† Getting Started",
    "section": "2.2 Modal setup",
    "text": "2.2 Modal setup\n$ modal setup\n\nThe web browser should have opened for you to authenticate and get an API token.\nIf it didn't, please copy this URL into your web browser manually:\n\nhttps://modal.com/token-flow/tf-xxxxxxxxxxx\n\nWeb authentication finished successfully!\nToken is connected to the charlotte-llm workspace.\nVerifying token against https://api.modal.com\nToken verified successfully!\nToken written to /Users/ryan/.modal.toml in profile charlotte-llm."
  },
  {
    "objectID": "01_getting_started.html#running-our-function-locally-remotely-and-in-parallel",
    "href": "01_getting_started.html#running-our-function-locally-remotely-and-in-parallel",
    "title": "2¬† Getting Started",
    "section": "3.1 Running our function locally, remotely, and in parallel",
    "text": "3.1 Running our function locally, remotely, and in parallel\nThree different ways we can call that function:\n\nAs a regular local call on your computer, with f.local\nAs a remote call that runs in the cloud, with f.remote\nBy mapping many copies of f in the cloud over many inputs, with f.map\n\n$ cd 01_getting_started\n$ modal run hello_world.py\n‚úì Initialized. View run at https://modal.com/charlotte-llm/main/apps/ap-xxxxxxxxx\n‚úì Created objects.\n‚îú‚îÄ‚îÄ üî® Created mount /modal-examples/01_getting_started/hello_world.py\n‚îî‚îÄ‚îÄ üî® Created function f.\nhello 1000\n1000000\n1000000\nhello 1000\nhello 0\nworld 1\nhello 2\nworld 3\nhello 4\nworld 5\nhello 6\nworld 7\nhello 8\nworld 9\nhello 10\nworld 11\nhello 12\nworld 13\nhello 14\nworld 15\nhello 16\nworld 17\nhello 18\nworld 19\n2470\nStopping app - local entrypoint completed.\n‚úì App completed. View run at https://modal.com/charlotte-llm/main/apps/ap-xxxxxxxxx\n\n3.1.1 What just happened?\nWhen we called .remote on f, the function was executed in the cloud, on Modal‚Äôs infrastructure, not locally on our computer.\nIn short, we took the function f, put it inside a container, sent it the inputs, and streamed back the logs and outputs.\n\n\n3.1.2 But why does this matter?\nTry doing one of these things next to start seeing the full power of Modal!\n\n\n3.1.3 Change the code\nI‚Äôll change the print to ‚Äúspam‚Äù and ‚Äúeggs‚Äù:\n\n\nhello_world_spam.py\n\nimport sys\nimport modal\n\napp = modal.App(\"example-hello-world\")\n\n@app.function()\ndef f(i):\n    if i % 2 == 0:\n        print(\"spam\", i)\n    else:\n        print(\"eggs\", i, file=sys.stderr)\n\n    return i * i\n\n@app.local_entrypoint()\ndef main():\n    # run the function locally\n    print(f.local(1000))\n\n    # run the function remotely on Modal\n    print(f.remote(1000))\n\n    # run the function in parallel and remotely on Modal\n    total = 0\n    for ret in f.map(range(20)):\n        total += ret\n\n    print(total)\n\nThen run:\n$ modal run hello_world_spam.py\n‚úì Initialized. View run at https://modal.com/charlotte-llm/main/apps/ap-xxxxxxxxx\n‚úì Created objects.\n‚îú‚îÄ‚îÄ üî® Created mount /modal-examples/01_getting_started/hello_world_spam.py\n‚îî‚îÄ‚îÄ üî® Created function f.\nspam 1000\n1000000\nspam 1000\n1000000\nspam 0\neggs 1\nspam 2\neggs 3\nspam 4\neggs 5\nspam 6\neggs 7\nspam 8\neggs 9\nspam 10\neggs 11\nspam 12\neggs 13\nspam 14\neggs 15\nspam 16\neggs 17\nspam 18\neggs 19\n2470\nStopping app - local entrypoint completed.\n‚úì App completed. View run at https://modal.com/charlotte-llm/main/apps/ap-xxxxxxxxx\nI can view the output via browser:\n\nThis example is obviously very simple, but there are many other things you can do with modal like:\n\nRunning language model inference or fine-tuning\nManipulating audio or images\nCollecting financial data to backtest a trading algorithm."
  },
  {
    "objectID": "01_getting_started.html#decorators",
    "href": "01_getting_started.html#decorators",
    "title": "2¬† Getting Started",
    "section": "4.1 Decorators",
    "text": "4.1 Decorators\nNotice the two different app decorators: @app.function() and @app.local_entrypoint().\n\n\n\n\n\n\nFrom the docs, a local_entrypoint:\n\n\n\n&gt; def local_entrypoint(\n    self, _warn_parentheses_missing=None, *, name: Optional[str] = None\n) -&gt; Callable[[Callable[..., Any]], None]:\nDecorate a function to be used as a CLI entrypoint for a Modal App.\nThese functions can be used to define code that runs locally to set up the app, and act as an entrypoint to start Modal functions from. Note that regular Modal functions can also be used as CLI entrypoints, but unlike local_entrypoint, those functions are executed remotely directly.\n@app.local_entrypoint()\ndef main():\n    some_modal_function.remote()\nYou can call the function using modal run directly from the CLI:\nmodal run app_module.py\nNote that an explicit app.run() is not needed, as an app is automatically created for you.\n\n\nWe can run:\n$ modal run get_started.py     \n‚úì Initialized. View run at https://modal.com/charlotte-llm/main/apps/ap-xxxxxxxxx\n‚úì Created objects.\n‚îú‚îÄ‚îÄ üî® Created mount /modal-examples/01_getting_started/get_started.py\n‚îî‚îÄ‚îÄ üî® Created function square.\nthe square is 1764\nThis code is running on a remote worker!\nStopping app - local entrypoint completed.\n‚úì App completed. View run at https://modal.com/charlotte-llm/main/apps/ap-xxxxxxxxx\nNow I wonder what happens if I create a similar new file:\n\n\nget_started_local.py\n\nimport modal\n\napp = modal.App(\"example-get-started-local\")\n\n\n@app.function()\ndef square(x):\n    print(\"This code is running on a local worker!\")\n    return x**2\n\n\n@app.local_entrypoint()\ndef main():\n    print(\"the square is\", square.local(42))\n\nAnd then run:\n$ modal run get_started_local.py\n‚úì Initialized. View run at https://modal.com/charlotte-llm/main/apps/ap-xxxxxxxxxx\n‚úì Created objects.\n‚îú‚îÄ‚îÄ üî® Created mount /modal-examples/01_getting_started/get_started_local.py\n‚îî‚îÄ‚îÄ üî® Created function square.\nThis code is running on a local worker!\nthe square is 1764\nStopping app - local entrypoint completed.\n‚úì App completed. View run at https://modal.com/charlotte-llm/main/apps/ap-xxxxxxxxxx\nVery similar. What happens when we look at the logs:"
  },
  {
    "objectID": "02_building_containers.html#import_sklearn.py",
    "href": "02_building_containers.html#import_sklearn.py",
    "title": "3¬† Building Containers",
    "section": "3.1 import_sklearn.py",
    "text": "3.1 import_sklearn.py\n\n3.1.1 Install scikit-learn in a custom image\nThis builds a custom image which installs the sklearn (scikit-learn) Python package in it. It‚Äôs an example of how you can use packages, even if you don‚Äôt have them installed locally.\nFirst, the imports:\nimport time\nimport modal\nNext, we‚Äôll define an app, with a custom image that installs sklearn.\napp = modal.App(\n    \"import-sklearn\",\n    image=modal.Image.debian_slim()\n    .apt_install(\"libgomp1\")\n    .pip_install(\"scikit-learn\"),\n)\n\n\n\n\n\n\nChaining\n\n\n\nA nice design in modal is the idea of method chaining, where the image is built by layers.\n\n\nThe app.image.imports() lets us conditionally import in the global scope. This is needed because we might not have sklearn and numpy installed locally, but we know they are installed inside the custom image.\nwith app.image.imports():\n    import numpy as np\n    from sklearn import datasets, linear_model\nNow, let‚Äôs define a function that uses one of scikit-learn‚Äôs built-in datasets and fits a very simple model (linear regression) to it.\n@app.function()\ndef fit():\n    print(\"Inside run!\")\n    t0 = time.time()\n    diabetes_X, diabetes_y = datasets.load_diabetes(return_X_y=True)\n    diabetes_X = diabetes_X[:, np.newaxis, 2]\n    regr = linear_model.LinearRegression()\n    regr.fit(diabetes_X, diabetes_y)\n    return time.time() - t0\nFinally, we‚Äôd trigger the run locally. We also time this. Note that the first time we run this, it will build the image. This might take 1-2 min. When we run this subsequent times, the image is already build, and it will run much much faster.\nif __name__ == \"__main__\":\n    t0 = time.time()\n    with app.run():\n        t = fit.remote()\n        print(\"Function time spent:\", t)\n    print(\"Full time spent:\", time.time() - t0)\nLet‚Äôs now run it all:\n$ modal run import_sklearn.py \n‚úì Initialized. View run at https://modal.com/charlotte-llm/main/apps/ap-xxxxxxxxxx\nBuilding image im-m9EoOtS0dmWsGUat8WCWFc\n\n=&gt; Step 0: FROM base\n\n=&gt; Step 1: RUN apt-get update\nGet:1 http://deb.debian.org/debian bullseye InRelease [116 kB]\nGet:2 http://deb.debian.org/debian-security bullseye-security InRelease [48.4 kB]\nGet:3 http://deb.debian.org/debian bullseye-updates InRelease [44.1 kB]\nGet:4 http://deb.debian.org/debian bullseye/main amd64 Packages [8068 kB]\nGet:5 http://deb.debian.org/debian-security bullseye-security/main amd64 Packages [275 kB]\nGet:6 http://deb.debian.org/debian bullseye-updates/main amd64 Packages.diff/Index [26.3 kB]\nGet:7 http://deb.debian.org/debian bullseye-updates/main amd64 Packages T-2023-12-29-1403.39-F-2023-07-31-2005.11.pdiff [6053 B]\nGet:7 http://deb.debian.org/debian bullseye-updates/main amd64 Packages T-2023-12-29-1403.39-F-2023-07-31-2005.11.pdiff [6053 B]\nGet:8 http://deb.debian.org/debian bullseye-updates/main amd64 Packages [18.8 kB]\nFetched 8602 kB in 4s (2239 kB/s)\nReading package lists...\n\n=&gt; Step 2: RUN apt-get install -y libgomp1\nReading package lists...\nBuilding dependency tree...\nReading state information...\nlibgomp1 is already the newest version (10.2.1-6).\nlibgomp1 set to manually installed.\n0 upgraded, 0 newly installed, 0 to remove and 46 not upgraded.\nCreating image snapshot...\nFinished snapshot; took 1.14s\n\nBuilt image im-m9EoOtS0dmWsGUat8WCWFc in 8.53s\nBuilding image im-Kndkz3TpRhPEMy6UcNR7YR\n\n=&gt; Step 0: FROM base\n\n=&gt; Step 1: RUN python -m pip install scikit-learn \nLooking in indexes: http://pypi-mirror.modal.local:5555/simple\nCollecting scikit-learn\n  Downloading http://pypi-mirror.modal.local:5555/simple/scikit-learn/scikit_learn-1.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.3 MB)\n     ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 13.3/13.3 MB 169.9 MB/s eta 0:00:00\nRequirement already satisfied: numpy&gt;=1.19.5 in /usr/local/lib/python3.10/site-packages (from scikit-learn) (1.25.0)\nCollecting scipy&gt;=1.6.0 (from scikit-learn)\n  Downloading http://pypi-mirror.modal.local:5555/simple/scipy/scipy-1.13.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.6 MB)\n     ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 38.6/38.6 MB 233.1 MB/s eta 0:00:00\nCollecting joblib&gt;=1.2.0 (from scikit-learn)\n  Downloading http://pypi-mirror.modal.local:5555/simple/joblib/joblib-1.4.2-py3-none-any.whl (301 kB)\n     ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 301.8/301.8 kB 252.9 MB/s eta 0:00:00\nCollecting threadpoolctl&gt;=3.1.0 (from scikit-learn)\n  Downloading http://pypi-mirror.modal.local:5555/simple/threadpoolctl/threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\nInstalling collected packages: threadpoolctl, scipy, joblib, scikit-learn\nSuccessfully installed joblib-1.4.2 scikit-learn-1.5.0 scipy-1.13.1 threadpoolctl-3.5.0\n\n[notice] A new release of pip is available: 23.1.2 -&gt; 24.0\n[notice] To update, run: pip install --upgrade pip\nCreating image snapshot...\nFinished snapshot; took 2.27s\n\nBuilt image im-Kndkz3TpRhPEMy6UcNR7YR in 13.14s\n‚úì Created objects.\n‚îú‚îÄ‚îÄ üî® Created mount /modal-examples/02_building_containers/import_sklearn.py\n‚îî‚îÄ‚îÄ üî® Created function fit.\nInside run!\nStopping app - local entrypoint completed.\n‚úì App completed. View run at https://modal.com/charlotte-llm/main/apps/ap-xxxxxxxxxx\nSo from the above, it took 8.53s to build the first image, 2.27s to create the snapshot and 13.14s to build the second image. But if we run this again, it‚Äôll be much faster than before as we‚Äôve already."
  },
  {
    "objectID": "02_building_containers.html#import_sklearn_r2.py",
    "href": "02_building_containers.html#import_sklearn_r2.py",
    "title": "3¬† Building Containers",
    "section": "3.2 import_sklearn_r2.py",
    "text": "3.2 import_sklearn_r2.py\nJust for fun, let‚Äôs modify this script to now output the R^2 value on the test data.\n\n\nimport_sklearn_r2.py\n\nimport time\nimport modal\n\napp = modal.App(\n    \"import-sklearn\",\n    image=modal.Image.debian_slim()\n    .apt_install(\"libgomp1\")\n    .pip_install(\"scikit-learn\"),\n)\n\nwith app.image.imports():\n    import numpy as np\n    from sklearn import datasets, linear_model\n    from sklearn.model_selection import train_test_split\n    from sklearn.metrics import r2_score\n\n@app.function()\ndef fit():\n    print(\"Inside run!\")\n    X, y = datasets.load_diabetes(return_X_y=True)\n    X = X[:, np.newaxis, 2]\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n    regr = linear_model.LinearRegression()\n    regr.fit(X_train, y_train)\n    predict = regr.predict(X_test)\n    \n    return r2_score(predict, y_test)\n\n\nif __name__ == \"__main__\":\n    t0 = time.time()\n    with app.run():\n        t = fit.remote()\n        print(\"R Squared is:\", t)\n    print(\"Full time spent:\", time.time() - t0)\n\nRunning this, we get:\n$ modal run import_sklearn_r2.py\n‚úì Initialized. View run at https://modal.com/charlotte-llm/main/apps/ap-xxxxxxxxx\n‚úì Created objects.\n‚îú‚îÄ‚îÄ üî® Created mount /modal-examples/02_building_containers/import_sklearn_r2.py\n‚îî‚îÄ‚îÄ üî® Created function fit.\nInside run!\nStopping app - local entrypoint completed.\n‚úì App completed. View run at https://modal.com/charlotte-llm/main/apps/ap-xxxxxxxxxx\nThis result somewhat surprised me.\nFirst, I didn‚Äôt see the output R^2. I was expecting this perhaps the first time running, but didn‚Äôt see it.\nSecond, after running, unlike the previous example that shut down immediately, this container was running ephemerally:\n\nSo let‚Äôs rerun, but this time renaming our function from fit to fit_r2:\n$ modal run import_sklearn_r2.py\n‚úì Initialized. View run at https://modal.com/charlotte-llm/main/apps/ap-xxxxxxxxxx\n‚úì Created objects.\n‚îú‚îÄ‚îÄ üî® Created mount /modal-examples/02_building_containers/import_sklearn_r2.py\n‚îî‚îÄ‚îÄ üî® Created function fit_r2.\nInside run!\nStopping app - local entrypoint completed.\n‚úì App completed. View run at https://modal.com/charlotte-llm/main/apps/ap-xxxxxxxxxx\nThis avoided the issue of perpetually running but didn‚Äôt print the R^2 to console:\n\nThe main takeaway is to keep an eye on the naming of remote functions."
  },
  {
    "objectID": "02_building_containers.html#install_cuda.py",
    "href": "02_building_containers.html#install_cuda.py",
    "title": "3¬† Building Containers",
    "section": "3.3 install_cuda.py",
    "text": "3.3 install_cuda.py\nThe next examples shows how to use the Nvidia CUDA base image from DockerHub.\nHere‚Äôs a list of the different CUDA images available.\nWe need to add Python 3 and pip with the add_python option because the image doesn‚Äôt have these by default.\n\n\ninstall_cuda.py\n\nfrom modal import App, Image\n\nimage = Image.from_registry(\n    \"nvidia/cuda:12.2.0-devel-ubuntu22.04\", add_python=\"3.11\"\n)\napp = App(image=image)\n\n@app.function(gpu=\"T4\")\ndef f():\n    import subprocess\n\n    subprocess.run([\"nvidia-smi\"])\n\nRunning it provides:\n$ modal run install_cuda.py     \n‚úì Initialized. View run at https://modal.com/charlotte-llm/main/apps/ap-xxxxxxxxxx\nBuilding image im-NAV0762Ag7PgTCJY8XyAqb\n\n=&gt; Step 0: FROM nvidia/cuda:12.2.0-devel-ubuntu22.04\nGetting image source signatures\nCopying blob sha256:9a9dd462fc4c5ca1dd29994385be60a5bb359843fc93447331b8c97dfec99bf9\nCopying blob sha256:9fe5ccccae45d6811769206667e494085cb511666be47b8e659087c249083c3f\nCopying blob sha256:aece8493d3972efa43bfd4ee3cdba659c0f787f8f59c82fb3e48c87cbb22a12e\nCopying blob sha256:bdddd5cb92f6b4613055bcbcd3226df9821c7facd5af9a998ba12dae080ef134\nCopying blob sha256:8054e9d6e8d6718cc3461aa4172ad048564cdf9f552c8f9820bd127859aa007c\nCopying blob sha256:5324914b447286e0e6512290373af079a25f94499a379e642774245376e60885\nCopying blob sha256:95eef45e00fabd2bce97586bfe26be456b0e4b3ef3d88d07a8b334ee05cc603c\nCopying blob sha256:e2554c2d377e1176c0b8687b17aa7cbe2c48746857acc11686281a4adee35a0a\nCopying blob sha256:4640d022dbb8eb47da53ccc2de59f8f5e780ea046289ba3cffdf0a5bd8d19810\nCopying blob sha256:aa750c79a4cc745750c40a37cad738f9bcea14abb96b0c5a811a9b53f185b9c9\nCopying blob sha256:9e2de25be969afa4e73937f8283a1100f4d964fc0876c2f2184fda25ad23eeda\nCopying config sha256:fead46ae620f9febc59f92a8f1f277f502ef6dca8111ce459c154d236ee84eee\nWriting manifest to image destination\nUnpacking OCI image\n   ‚Ä¢ unpacking rootfs ...\n   ‚Ä¢ ... done\n   ‚Ä¢ unpacked image rootfs: /tmp/.tmpDUhHRA\n\n=&gt; Step 1: COPY /python/. /usr/local\n\n=&gt; Step 2: RUN ln -s /usr/local/bin/python3 /usr/local/bin/python\n\n=&gt; Step 3: ENV TERMINFO_DIRS=/etc/terminfo:/lib/terminfo:/usr/share/terminfo:/usr/lib/terminfo\n\n=&gt; Step 4: COPY /modal_requirements.txt /modal_requirements.txt\n\n=&gt; Step 5: RUN python -m pip install --upgrade pip\nLooking in indexes: http://pypi-mirror.modal.local:5555/simple\nRequirement already satisfied: pip in /usr/local/lib/python3.11/site-packages (23.2.1)\nCollecting pip\n  Obtaining dependency information for pip from http://pypi-mirror.modal.local:5555/simple/pip/pip-24.0-py3-none-any.whl.metadata\n  Downloading http://pypi-mirror.modal.local:5555/simple/pip/pip-24.0-py3-none-any.whl.metadata (3.6 kB)\nDownloading http://pypi-mirror.modal.local:5555/simple/pip/pip-24.0-py3-none-any.whl (2.1 MB)\n   ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2.1/2.1 MB 216.4 MB/s eta 0:00:00\nInstalling collected packages: pip\n  Attempting uninstall: pip\n    Found existing installation: pip 23.2.1\n    Uninstalling pip-23.2.1:\n      Successfully uninstalled pip-23.2.1\nSuccessfully installed pip-24.0\n\n=&gt; Step 6: RUN python -m pip install -r /modal_requirements.txt\nLooking in indexes: http://pypi-mirror.modal.local:5555/simple\nIgnoring cloudpickle: markers 'python_version &lt; \"3.11\"' don't match your environment\nIgnoring ddtrace: markers 'python_version &lt; \"3.11\"' don't match your environment\nCollecting aiohttp==3.8.3 (from -r /modal_requirements.txt (line 2))\n\n...\n\nCreating image snapshot...\nFinished snapshot; took 6.10s\n\nBuilt image im-NAV0762Ag7PgTCJY8XyAqb in 136.43s\n‚úì Created objects.\n‚îú‚îÄ‚îÄ üî® Created mount /modal-examples/02_building_containers/install_cuda.py\n‚îî‚îÄ‚îÄ üî® Created function f.\n\n==========\n== CUDA ==\n==========\n\nCUDA Version 12.2.0\n\nContainer image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.\n\nThis container image and its contents are governed by the NVIDIA Deep Learning Container License.\nBy pulling and using the container, you accept the terms and conditions of this license:\nhttps://developer.nvidia.com/ngc/nvidia-deep-learning-container-license\n\nA copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience.\n\nThu Jun 13 23:08:03 2024       \n+-----------------------------------------------------------------------------------------+\n| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n|-----------------------------------------+------------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n|                                         |                        |               MIG M. |\n|=========================================+========================+======================|\n|   0  Tesla T4                       On  |   00000000:36:00.0 Off |                 ERR! |\n| N/A   32C ERR!               9W /   70W |       0MiB /  15360MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n                                                                                         \n+-----------------------------------------------------------------------------------------+\n| Processes:                                                                              |\n|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n|        ID   ID                                                               Usage      |\n|=========================================================================================|\n|  No running processes found                                                             |\n+-----------------------------------------------------------------------------------------+\nStopping app - local entrypoint completed.\n‚úì App completed. View run at https://modal.com/charlotte-llm/main/apps/ap-xxxxxxxxxx\nWhile this process did take a few minutes, it‚Äôs very easy and should be very quick if rerunning.\nIt‚Äôs also helpful to note how to run a subprocess as we would in Python anyways:\nimport subprocess\n\nsubprocess.run([\"nvidia-smi\"])"
  },
  {
    "objectID": "02_building_containers.html#screenshot.py",
    "href": "02_building_containers.html#screenshot.py",
    "title": "3¬† Building Containers",
    "section": "3.4 screenshot.py",
    "text": "3.4 screenshot.py\nLast, we‚Äôll finish"
  }
]